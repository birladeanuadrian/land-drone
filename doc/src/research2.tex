\chapter{Bibliographic research}
\label{ch:research}

% https://www.ericsson.com/en/reports-and-papers/white-papers/drones-and-networks-ensuring-safe-and-secure-operations
% https://web.stanford.edu/class/cs231a/prev_projects_2016/deep-drone-object__2_.pdf

\section{Remote Drone Control}
\label{sec:research-remote-drone-control}
The article ~\cite{ericsson1} also approaches the topic of drone control. \
According ot it, most current drone use cases cover the situation in which the drone \
operator is in line of sight of the drone and has full control over it, with autonomous \
drones operating outside line of sight gaining more and more importance today. \
However, in the future the most common drone use cases will be the ones in which the drone \
operates autonomously outside line of sight ir without supervision.

\begin{figure}[ht]
    \label{fig:drone-uses}
    %\centering
    \includegraphics[width=15cm, height=50cm,keepaspectratio]{img/drone_uses.png}
    \caption{Drone Uses according to ~\cite{ericsson1}}
\end{figure}

In ~\cite{ericsson1} the author mentions three different options for drone communication and control:
\begin{enumerate}
    \item \textbf{satellite technology} is currently in use today for some drones; \
            its drawbacks include high latency and costs and low throughput
    \item \textbf{dedicated drone terrestrial network} its drawbacks also include high \
            costs and the time it would take to setup an adequate coverage for drones
    \item \textbf{existing terrestrial mobile networks} they have low latency and costs and \
            high throughput; \
            additionally, they have also proven to be secure and robust
\end{enumerate}

Additionally, other requirements can be accomplished using 4G LTE and 5G features. \
For instance, drone tracking can be implemented using the mobile positioning service and \
could be queried from the mobile network.

Drone control is also mentioned in ~\cite{forbes1} . \
The article also mentions 2 possible control methods that are actively used and that \
partially overlap over those mentioned above. \
These are:
\begin{enumerate}
    \item \textbf{radio waves} these have limited range (an example of 100 miles is given);
    \item \textbf{satellite uplink} it takes footage an average 1.2-second delay to go from \
            a drone in Afghanistan to the operator in Virginia
\end{enumerate}

~\cite{forbes1} also does a classification of drones according to how they are commanded. \
Three classes of drones emerge:
\begin{enumerate}
    \item \textbf{remotely piloted} an operator has full control, while the drone can do \
            minimal actions by its own, like avoid crashing
    \item \textbf{semi-autonomous} the drone can perform all or some missions without any \
            human interaction, however an operator exists that can take over control at \
            any time
    \item \textbf{fully autonomous} the drone is engineered to accomplish its mission \
            without any human interaction or supervision; \
            the command link can be missing
\end{enumerate}

\section{Object Detection}
\label{sec:research-object-detection}
In recent years, convolutional neural networks have been used more and more in \
the field of object detection. \
According to ~\cite{deepLearning}, A convolutional neural network (CNN) is a \
subclass of multilayer neural networks in which at least one layer applies \
a convolution on its input data instead of matrix multiplication.\
CNNs have seen a rise in use in object detection since 2012, when \
a CNN developed by ~\cite{imagenet} won the ImageNet Large Scale Visual \
Recognition Challenge for the first time. \
The CNN managed to reduce the top-1 (actual label differs from predicted label) \
 and top-5 (actual label is not in the predicted top 5 most likely labels) \
error rates from 47.1\% respectively 28.2\% to 37.5\% respectively 17\%. \
Additionally, the authors mentioned that the performance was limited by the \
existing hardware and dataset
Ever since, the contest has been won by convolutional neural networks. \
By 2016, the top-5 error rate dropped to 3.6\%.

% todo: mention SSD vs YOLO


In the paper~\cite{deepDrone}, the authors also attempt to create a drone capable \
of detecting people, with a few differences:
\begin{itemize}
    \item the drone is an airborne one
    \item image processing is done on the drone itself
\end{itemize}

The authors designed an algorithm to detect and track a single person at a time.
They used a Faster RCNN neural network to detect a person.
Once the drone detected an object, it stopped applying the neural network on \
new images.
Instead, it applied a KCF tracking algorithm as longs as the object was still in \
the image.
Once the KCF algorithm detected that he object was no longer in the image, \
the drone stopped applying the tracking algorithm and switched back to the \
detection neural network.
The authors also experimented with a YOLO detector, but they found that although it is \
faster than Faster RCNN, it is less accurate, especially when it comes to small and \
remote people.

The authors tested the tracking and detection algorithms on multiple GPUs, with the \
results shown in th table below:

\begin{table}[ht]
    \caption{Detection and Tracking Results}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline\hline
        Hardware Platform & GTX 980 & TX1 & TK1 \\
        \hline
        Power & 150W & 10W & 7W \\
        Detection & 0.17s & 0.6s & 1.6s \\
        Tracking & 5.5ms & 14ms & 14ms \\
        \hline
    \end{tabular}
    \label{table:deep-drone-results}
\end{table}

Since the image processing is done on the drone itself, the power consumption of \
the CPU and GPU must also be taken into consideration in order to determine the \
autonomy of the drone.

\section{Object Tracking}
\label{sec:research-tracking}
Some projects use object detection algorithms to detect an initial object, and \
then start applying tracking algorithsm and stop applying detection algorithsm \
because tracking algorithms are faster than the detection algorithms.

In ~\cite{OpencvTracking}, the author present a status of the most \
popular tracking algorithms from opencv.
After analysing multiple algorithms (CSRT, KCF, Boosting, MIL, TLD, \
MedianFlow, MOSSE, GOTURN), the author comes to the following \
conclusions:
\begin{itemize}
    \item \textbf{CSRT} should be used when higher tracking accuracy \
            is required and the program can tolerate a smaller throughput
    \item \textbf{KCF} should be used when the program requires greater \
            throughput and faster FPS at the expense of a slightly \
            lower accuracy
    \item \textbf{MOSSE} should be used when the speed is of absolute \
            importance
\end{itemize}

In ~\cite{OpencvTracking2} the author also compares the different \
tracking algorithms, adding the FPS for each algorithm.
The KCF tracker reached 409 FPS, but it failed to recover from full \
object occlusion.
The MOSSE tracker reached an astounding 2671 FPS, but it lacked \
behind deep learning based trackers in performance.
Even more, the author mentions that the algorithm looses precision \
even for objects in normal movement.
As for CSRT, it gives higher accuracy, but it reached only 32 FPS.


%Bibliographic research has as an objective the establishment of the references for the \
%project, within the project domain/thematic. While writing this chapter (in general the \
%whole document), the author will consider the knowledge accumulated from several \
%dedicated disciplines in the second semester, 4$^{th}$ year (Project Elaboration \
%Methodology, etc.), and other disciplines that are relevant to the project theme.
%
%Represents about 15\% of the paper.
%
%Each reference must be cited within the document text, see example below (depending \
%on the project theme, the presentation of a method/application can vary).
%
%
%This section includes citations for conferences or workshop~\cite{BellucciLZ04}, \
%journals~\cite{AntoniouSBDB07},
%and books~\cite{russell1995artificial}.
%
%In paper~\cite{AntoniouSBDB07} the authors present a detection system for moving obstacles based on stereovision and ego motion estimation.
%The method is ... {\it discus the algorithms, data structures, functionality, specific aspects related to the project theme, etc.}... Discussion: {\it pros and cons}.
%
%In chapter~\ref{ch:analysis} of~\cite{strunk}, the {\it similar-to-my-project-theme algorithm} is presented, with the following features ...
%
%
%\section{Title}
%\section{Other title}
